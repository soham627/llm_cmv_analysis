{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import tarfile\n",
    "import json\n",
    "from bz2 import BZ2File\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import csv\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fname = \"cmv.tar.bz2\"\n",
    "# make sure you have downloaded the dataset from https://chenhaot.com/data/cmv/cmv.tar.bz2\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    raise FileNotFoundError(f\"Dataset file {fname} not found. Please check your directory.\")\n",
    "\n",
    "tar = tarfile.open(fname, mode=\"r:bz2\")\n",
    "\n",
    "\n",
    "# extract the train and test pairs\n",
    "train_fname = \"pair_task/train_pair_data.jsonlist.bz2\"\n",
    "test_fname = \"pair_task/heldout_pair_data.jsonlist.bz2\"\n",
    "\n",
    "train_bzlist = tar.extractfile(train_fname)\n",
    "test_bzlist = tar.extractfile(test_fname)\n",
    "\n",
    "# load JSON data\n",
    "train_argument_pairs = [json.loads(line.decode('utf-8')) for line in BZ2File(train_bzlist)]\n",
    "test_argument_pairs = [json.loads(line.decode('utf-8')) for line in BZ2File(test_bzlist)]\n",
    "\n"
   ],
   "id": "98adb414dee2730b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_argument_text(argument):\n",
    "    \"\"\"Extracts clean argument text from JSON structure.\"\"\"\n",
    "    if isinstance(argument, dict) and \"comments\" in argument:\n",
    "        # extract first comment's body text\n",
    "        if isinstance(argument[\"comments\"], list) and len(argument[\"comments\"]) > 0:\n",
    "            return argument[\"comments\"][0].get(\"body\", \"\").strip()\n",
    "    return \"\"\n",
    "\n",
    "def format_prompt(sample):\n",
    "    \"\"\"Formats a single argument pair into a GPT-compatible prompt.\"\"\"\n",
    "\n",
    "    # extract components\n",
    "    original_post = sample[\"op_text\"]\n",
    "    counterargument_1 = extract_argument_text(sample[\"positive\"])  # Persuasive argument\n",
    "    counterargument_2 = extract_argument_text(sample[\"negative\"])  # Non-persuasive argument\n",
    "\n",
    "    if not counterargument_1 or not counterargument_2:\n",
    "        return None\n",
    "\n",
    "    # shuffle order\n",
    "    if random.random() > 0.5:\n",
    "        counterargument_1, counterargument_2 = counterargument_2, counterargument_1\n",
    "        correct_answer = \"2\"\n",
    "    else:\n",
    "        correct_answer = \"1\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant analyzing persuasion in online discussions. Below is an original post (OP) and two counterarguments.\n",
    "\n",
    "Your task:\n",
    "1. Predict which argument is more persuasive, (1) or (2), taking into account the original post.\n",
    "2. Justify your prediction based on reasoning, tone, and style.\n",
    "\n",
    "---\n",
    "\n",
    "Original Post (OP):\n",
    "\"{original_post}\"\n",
    "\n",
    "Counterargument 1:\n",
    "\"{counterargument_1}\"\n",
    "\n",
    "Counterargument 2:\n",
    "\"{counterargument_2}\"\n",
    "\n",
    "---\n",
    "\n",
    "**Response Format (follow this exactly!):**\n",
    "Prediction: [1 or 2]\n",
    "Explanation: [Your reasoning]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    return {\"prompt\": prompt, \"correct_answer\": correct_answer}\n",
    "\n",
    "# === Test on a Sample ===\n",
    "#formatted_sample = format_prompt(train_argument_pairs[0])\n",
    "\n",
    "# Ensure the function worked correctly\n",
    "'''if formatted_sample:\n",
    "    print(\"Formatted GPT Prompt:\")\n",
    "    print(formatted_sample[\"prompt\"])\n",
    "    print(f\"Correct Answer:{formatted_sample['correct_answer']}\")\n",
    "else:\n",
    "    print(\"\\n Skipped a sample due to missing argument text.\")'''\n"
   ],
   "id": "80fa11308e1de1b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "7974f19534ddf10f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def call_gpt(prompt, model=\"gpt-4o\", max_retries=3):\n",
    "    \"\"\"\n",
    "    Sends a prompt to the GPT (default value is 4o) and extracts:\n",
    "    - Prediction (1 or 2)\n",
    "    - Explanation for the prediction\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"You are an AI assistant that analyzes persuasive arguments. \"\n",
    "                            \"Given an original post and two counterarguments, you must: \"\n",
    "                            \"1. Predict which argument is more persuasive (1 or 2), considering the original post. \"\n",
    "                            \"2. Justify your prediction based on reasoning, tone, and style. \"\n",
    "                            \"Your response must strictly follow this format:\\n\"\n",
    "                            \"Prediction: [1 or 2]\\n\"\n",
    "                            \"Explanation: [Your reasoning]\"\n",
    "                        )\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=250\n",
    "            )\n",
    "\n",
    "            # get the raw response text\n",
    "            gpt_output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # extract the prediction\n",
    "            match = re.search(r\"Prediction:\\s*(1|2)\", gpt_output)\n",
    "            prediction = match.group(1) if match else \"Unknown\"\n",
    "\n",
    "            # extract explanation\n",
    "            explanation = gpt_output.split(\"Explanation:\", 1)[-1].strip() if \"Explanation:\" in gpt_output else gpt_output\n",
    "\n",
    "            return {\n",
    "                \"prediction\": prediction,\n",
    "                \"explanation\": explanation,\n",
    "                \"raw_response\": gpt_output\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Call failed (Attempt {attempt+1}/{max_retries}): {e}\")\n",
    "            time.sleep(2)\n",
    "\n",
    "    return {\n",
    "        \"prediction\": \"Error\",\n",
    "        \"explanation\": \"Failed to retrieve response\",\n",
    "        \"raw_response\": \"\"\n",
    "    }\n",
    "\n"
   ],
   "id": "162a5330ee0e3cec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "num_samples = 500\n",
    "\n",
    "# select a random sample from the data\n",
    "sampled_data = random.sample(train_argument_pairs, num_samples)\n",
    "gpt_prompts = [format_prompt(sample) for sample in sampled_data]\n",
    "\n",
    "\n",
    "gpt_prompts = [p for p in gpt_prompts if p is not None]\n",
    "\n",
    "output_file = \"gpt_results_4o.csv\"\n",
    "results = []\n",
    "\n",
    "for i, sample in enumerate(gpt_prompts):\n",
    "    print(f\"Processing sample {i+1}/{len(gpt_prompts)}...\")\n",
    "\n",
    "\n",
    "    response = call_gpt(sample[\"prompt\"], model=\"gpt-4o\")\n",
    "\n",
    "    results.append({\n",
    "        \"original_post\": sampled_data[i][\"op_text\"],\n",
    "        \"counterargument_1\": sampled_data[i][\"positive\"],\n",
    "        \"counterargument_2\": sampled_data[i][\"negative\"],\n",
    "        \"gpt_prediction\": response[\"prediction\"],\n",
    "        \"correct_answer\": sample[\"correct_answer\"],\n",
    "        \"explanation\": response[\"explanation\"]\n",
    "    })\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# save results\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"original_post\", \"counterargument_1\", \"counterargument_2\", \"gpt_prediction\", \"correct_answer\", \"explanation\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"Finished processing! Results saved.\")"
   ],
   "id": "218ac3e8ce1a4882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Same process but for 3.5\n",
    "num_samples = 500\n",
    "\n",
    "gpt_prompts = [format_prompt(sample) for sample in sampled_data]\n",
    "\n",
    "\n",
    "gpt_prompts = [p for p in gpt_prompts if p is not None]\n",
    "\n",
    "output_file = \"old/gpt_results_3_5.csv\"\n",
    "results = []\n",
    "\n",
    "for i, sample in enumerate(gpt_prompts):\n",
    "    print(f\"Processing sample {i+1}/{len(gpt_prompts)}...\")\n",
    "\n",
    "\n",
    "    response = call_gpt(sample[\"prompt\"], model=\"gpt-3.5-turbo\")\n",
    "\n",
    "    results.append({\n",
    "        \"original_post\": sampled_data[i][\"op_text\"],\n",
    "        \"counterargument_1\": sampled_data[i][\"positive\"],\n",
    "        \"counterargument_2\": sampled_data[i][\"negative\"],\n",
    "        \"gpt_prediction\": response[\"prediction\"],\n",
    "        \"correct_answer\": sample[\"correct_answer\"],\n",
    "        \"explanation\": response[\"explanation\"]\n",
    "    })\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# save results\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"original_post\", \"counterargument_1\", \"counterargument_2\", \"gpt_prediction\", \"correct_answer\", \"explanation\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"Finished processing! Results saved.\")"
   ],
   "id": "54f33d568845574a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c55e229fce01f2e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
